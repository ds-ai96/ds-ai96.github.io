---
layout: article
title: 눈문 리뷰 - NCF (Neural Collaborative Filtering)
sidebar:
    nav: docs-en
aside:
    toc: true
tags: 추천시스템 논문리뷰
key: page-about
---

## Paper Information

- Title : PURS: Personalized Unexpected Recommender System for Improving User Statisfaction
- Authors : Xiangnan He et al.
- Conference : WWW'17
- URL : [논문 링크](https://dl.acm.org/doi/pdf/10.1145/3038912.3052569)

---

# 1. Introduction

개인화된 추천 시스템 (Personalized recommender system)의 핵심은 **협업 필터링** (collaborative filtering) 으로 과거의 상호작용 (예: ratings, clicks)을 기반으로 아이템들에 대한 사용자의 선호도를 모델링 하는 것이다.

다양한 협업 필터링 기법 중에서 *Matrix Factorization (MF)*가 가장 인기 있는 기법이며, 사용자와 아이템을 shared latent space에 투영하여 latent features의 벡터를 사용해서 사용자 또는 아이템을 표현한다. 그 후에 아이템에 대한 사용자의 관심 (interaction)을 latent vectors의 내적 (inner product)로 모델링한다.

- MF가 협업 필터링에서 유명한 방법이지만, 단순한 interaction function(내적) 때문에 성능이 저해된다.

latent features을 단순하게 선형으로 결합하는 내적은 복잡한 사용자 상호작용 데이터 구조를 포착하기에 불충분하다.

따라서, 본 연구는 협업 필터링을 위한 신경망 모델링 접근법을 제안한다.

- Implicit Feedback

    Implicit feedback은 영상 시청, 물품 구매 및 아이템 클릭과 같은 행동을 통해서 사용자의 선호도를 간접적으로 반영한다.

    Explicit feedback (예: 등급, 리뷰)와 비교해서 implicit feedback은 자동으로 추적될 수 있기 때문에, 더 쉽게 수집될 수 있다. 그러나, 사용자의 만족도가 관측되지 않고 negative feedback가 부족하기 때문에 활용하기는 더 어렵다.

### Contribution

1. 사용자와 아이템들의 latent features을 모델링하기 위한 신경망 구조를 제시하고 신경망 기반의 협업 필터링을 위한 NCF를 고안한다.
2. MF가 NCF의 특수한 경우로 해석될 수 있고 다층 퍼셉트론을 활용해서 NCF 모델링에 높은 수준의 비선형성을 부여할 수 있음을 보인다.
3. NCF 접근법의 효율성과 협업 필터링을 위한 딥러닝의 가능성을 증명하기 위해서 실제 데이터셋에서 실험을 진행한다.    

---
# 2. Preliminaries

문제를 공식화하고 implicit feedback을 사용하는 협업 필터링을 위한 기존의 방법에 대해서 논의한다.

내적을 사용하는 경우의 한계를 강조하면서, 주로 사용되는 MF 모델에 대해서 설명한다.

## 2.1 Learning from Implicit Data

$M$과 $N$을 각각 사용자와 아이템의 수라고 두면, 사용자의 implicit feedback로 부터 사용자-아이템 interact matrix $\mathbf{Y}  \in \mathbb{R}^{M \times N}$은 다음과 같다:

$$y_{ui} = \begin{cases} 1, & \text{if interaction (user } u\text{, item }i\text{) is ovserved;} \\ 0, & \text{otherwise.} \end{cases}$$

- $y_{ui}$가 1이면, 사용자 $u$와 아이템 $i$사이에 상호작용이 있다. 하지만, 그것이 $u$가 실제로 $i$를 좋아한다는 것을 의미하지는 않는다.
- 마찬가지로, 값이 0이라는 것이 사용자 $u$가 아이템 $i$를 좋아하지 않는 것은 아니다. 단순히 사용자가 아이템을 인식하지 못한 것이라고 할 수 있다.

    **그렇기 때문에 implicit를 사용해서 학습하는 것이 어렵다.**

  - Observed entries : 최소한 아이템에 대한 사용자의 관심(interest)을 반영
  - Unobserved entris : 누락된 값(missing data)일 수 있기 때문에, negative feedback이 부족하다.

Implicit feedback이 있는 추천 문제는 $\mathbf{Y}$에서 unobserved entries에 대한 점수를 추정하는 문제로 공식화된다.

모델 기반의 접근 방법을 형식적으로 표현하면 $\hat{y}_{ui} = f(u, i | \Theta)$로 형식화 할 수 있다.

- $\hat{y}_{ui}$: 상호작용 $y_{ui}$의 예측된 점수
- $\Theta$: 추정해야 하는 파라미터들
- $f$: 모델 파라미터를 예측된 점수로 맵핑하는 함수

파라미터들인 $\Theta$를 추정하기 위해서 기존의 방법들은 일반적으로 목적 함수(object function)을 최적화하는 머신 러닝 접근법을 따른다.

- pointwise loss

    pointwise loss 방법은 일반적으로 $\hat{y}_{ui}$와 $y_{ui}$ 사이의 제곱 손실을 최소화하는 회귀 프레임워크를 따른다.

    negative feedback가 Implicit feedback에는 존재하지 않기 때문에, 관측되지 않은 값은 모두 부정적인 피드백으로 처리하거나 관측되지 않은 아이템들에서 부정적인 인스턴스를 샘플링(Negative Sampling)한다.

- pairwise loss

    관측된 항목들은 반드시 관측되지 않은 항목보다 높게 랭크될 것이라는 가정이 필요하다.

    관측된 항목 $\hat{y}_{ui}$와 $\hat{y}_{uj}$의 margin을 최대화하는 방향으로 훈련한다.

=> NCF는 pointwise와 pairwise을 모두 지원한다.


## 2.2 Matrixcx Factorization

Matrix Factorization (MF)는 각 사용자와 아이템을 잠재 특성의 실수값 벡터로 연관짓는다.

$\mathbf{p}_u$와 $\mathbf{q}_i$를 각각 사용자 $u$와 사용자 $i$의 잠재 벡터라고 두면, MF는 상호작용 $y_{ui}$를 $\mathbf{p}_u$와 $\mathbf{q}_i$의 내적으로 다음과 같이 추정한다.

$$\hat{y}_{ui} = f(u, i | \mathbf{p}_u, \mathbf{q}_i) = \mathbf{p}_U^T \mathbf{q}_i = \sum_{k=1}^K p_{uk}q_{ik},$$

여기서, $K$는 잠재 공간의 차원이다.

MF는 잠재 공간의 각 차원이 서로 독립이라고 가정하고 동일한 가중치로 선형적으로 결합하기 때문에, MF는 잠재 요소들의 선형모델로 보여질 수 있다.

![Figure1](/image/RS-Paper-No3/RS-Paper-No3-Fig1.png)

1. MF는 사용자와 아이템을 동일한 잠재 공간에 매핑하기 때문에 유사성은 내적 또는 코사인으로 측정할 수 있다.
2. Jaccaard 계수를 MF가 복원해야 하는 두 사용자의 ground-truth 유사도로 사용한다.

그림 1 (a)에서 $u_4$는 $u_1$와 가장 유사하고, 다음으로 $u_3$, $u_2$ 순서로 비슷하다. 하지만, (b)에서 $u_4$를 표현하는 데 이상한 부분이 보인다. 이 예시는 저차원의 잠재 공간에서 복잡한 사용자-아이템 상호작용을 추정하기 위해서 단순한 내적을 사용하여 발생하는 MF의 한계를 보여준다.

이 문제를 해결하기 위한 한 방법은 가능한 큰 $K$를 사용하는 것이지만, 이러한 희소한 환경에서는 모델의 일반화에 부정적인 효과를 줄 수 있다.

=> 본 연구에서는 DNNs를 사용하여 상호 작용 함수를 학습하여 한계를 해결하고자 한다.

---

# 3. Neural Collaborative Filtering

1. 일반적인 NCF 프레임워크로 implicit data의 binary property을 강조하는 확률론적 모델(probabilistic model)로 NCF를 학습하는 방법 설명.
2. MF가 NCF에 의해 표현되고 일반화될 수 있음을 보인다.
3. MLP를 사용해서 사용자-아이템 상호작용 함수를 학습하도록 NCF의 인스턴스를 제안.
4. 사용자-아이템 잠재 구조를 모델링하기 위해서 MF의 선형성과 MLP의 비선형성이라는 강점을 결합하는 새로운 neural matrix factorization 모델인 NCF 프레임워크를 제안.

## 3.1 General Framework

![Figure2](/image/RS-Paper-No3/RS-Paper-No3-Fig2.png)

1. Input Layer (Sparse)

    두 개의 특성 벡터(feature vector) $\mathbf{v}_u^\mathbf{U}$와 $\mathbf{v}_i^\mathbf{I}$는 각각 사용자 $u$와 아이템 $i$를 설명한다.

    Context-aware, content-based 및 neighbor-based 등 다양한 방법으로 모델링 될 수 있지만, 본 논문에서는 단순히 원-핫 인코딩을 사용해서 이진화된 희소 벡터를 사용했다.

2. Embedding Layer

    희소 표현 (sparse representation)을 dense vector로 투영하는 완전 연결 계층(fully connected layer)이다. 결과로 얻어진 사용자 (아이템) 임베딩은 latent factor model의 관점에서 사용자 (아이템)에 대한 잠재 벡터로 볼 수 있다.

    이후, 잠재 벡터를 예측 점수로 매핑하는 Neural Collaborative Filtering Layers라고 불리는 multi-layer neural 구조로 사용자 임베딩과 아이템 임베딩이 공급된다.

3. Neural CF Layers

    neural CF layers의 각 레이어는 사용자-아이템 상호작용의 특정 잠재 구조를 발견하도록 커스텀될 수 있다. 마지막 히든 레이어 X의 차원에 따라서 모델의 capability(용량)가 결정된다.

4. Output Layer

    $\hat{y}_{ui}$와 타겟값 $y_{ui}$ 간의 pointwise loss를 최소화하도록 훈련을 진행한다.

NCF의 예측 모델을 다음과 같이 공식화한다:

$$\hat{y}_{ui} = f(\mathbf{P}^T \mathbf{v}_u^U, \mathbf{Q}^T \mathbf{v}_i^I | \mathbf{P}, \mathbf{Q}, \Theta_f),$$

- $\mathbf{P} \in \mathbb{R}^{M \times K}$: 사용자에 대한 latent factor matrix
- $\mathbf{Q} \in \mathbb{R}^{N \times K}$: 아이템에 대한 latent factor matrix
- $\Theta_f$: 상호작용 함수 $f$에 대한 모델 파라미터들
- $f$: multi-layer neural network로 정의되며, 다음과 같이 수식으로 표현한다.

$$ f(\mathbf{P}^T \mathbf{v}_u^U, \mathbf{Q}^T \mathbf{v}_i^I) = \phi_{out}(\phi_X(... \phi_2(\phi_1 (\mathbf{P}^T \mathbf{v}_u^U, \mathbf{Q}^T \mathbf{v}_i^I)) ...))),$$

- $\phi_{out}$: output layer에 대한 mapping function
- $\phi_x$: $x$번째 neural collaborative filtering (CF) layer에 대한 mapping function
  
### 3.1.1 Learning NCF

모델 파라미터를 학습하기 위해서, 기존의 pointwise 방법은 크게 제곱 오차에 대한 회귀를 수행한다.

$$L_{sqr} = \sum_{(u, i) \in \mathcal{Y} \cup \mathcal{Y}^-} w_{ui} (y_{ui} - \hat{y}_{ui})^2,$$

- $\mathcal{Y}$: $\mathbf{Y}$에서 관측된 상호작용의 집합
- $\mathcal{Y^-}$: $\mathbf{Y}$에서 관측되지 않은 상호작용의 집합, nagative instances로 취급한다.
- $w_{ui}$: 훈련 인스턴스 $(u, i)$의 가중치를 나타내는 하이퍼파라미터

**제곱 오차는 관측치가 가우시한 분포에서 생성된다고 가정한다**. 하지만, Implicit data에서는 잘 맞지 않는다. 따라서, implicit data의 binary한 특성을 잘 학습할 수 있는 확률론적인 접근방법을 제시한다.

Implicit feedback의 one-class한 특성을 고려할 때, $y_{ui}$가 1이라는 것은 아이템 $i$와 사용자 $u$가 관련이 있다는 것을 의미하고, 그렇지 않다면 0을 의미한다.

-> 그렇다면 예측 점수 $\hat{y}_{ui}$는 얼마나 $i$와 $u$가 관련이 있는지를 나타낸다.

NCF에 이러한 확률론적인 설명을 추가하기 위해서, output layer에 확률론적 함수(*Logistic* or *Probit* function)을 활성화 함수로 사용해서 $[0, 1]$ 범위로 출력을 제한한다. 따라서, 다음과 같이 likelihood function을 정의한다:

$$p(\mathcal{Y}, \mathcal{Y}^- | \mathbf{P}, \mathbf{Q}. \Theta_f) = \prod_{(u,i) \in \mathcal{Y}} \hat{y}_{ui} \prod_{(u,j) \in \mathcal{Y}^-} (1 - \hat{y}_{uj}).$$

likelihood의 음수 로그를 취하면 다음과 같다:

$$L = - \sum_{(u,i) \in \mathcal{Y}} \log{\hat{y}_{ui}} - \sum_{(u,i) \in \mathcal{Y}^-} \log{(1 - \hat{y}_{uj})} \\ = - \sum_{(u,i) \in \mathcal{Y} \cup \mathcal{Y}^-} y_{ui} \log{\hat{y}_{ui}} + (1-y_{ui}) \log(1-\hat{y}_{ui}).$$

NCF 방법에 대해서 위의 식은 최소화해야 하는 목적 함수이며, 이것은 SGD를 사용해서 수행된다. 위의 식은 *log loss*라고 알려진 *binary cross-entropy loss*와 같다.

Nagative instance $\mathcal{Y}^-$의 경우에는, 각 반복에서 관측되지 않은 샘플에서 균일하게 샘플링하고 관측된 상호작용의 수에 대해서 샘플링 비율을 조절한다.

-> non-uniform sampling strategy가 성능을 향상시킬 수 있지만, 미래 연구로...


## 3.2 Generalized Matrix Factorization (GMF)

Input layer의 사용자 (아이템) ID의 원-핫 인코딩으로 얻어진 임베딩 벡터는 사용자(아이템)의 잠재 벡터로 볼 수 있다. 사용자 잠재 벡터 $\mathbf{p}_u$를 $\mathbf{P}^T \mathbf{v}_u^U$라 하고, 아이템 잠재 벡터 $\mathbf{q}_i$를 $\mathbf{Q}^T \mathbf{v}_i^I$라고 하자. 그러면 첫 번째 nueral CF layer의 매핑 함수를 다음과 같이 정의한다.

$$\phi_1 (\mathbf{p}_u, \mathbf{q}_i) = \mathbf{p}_u \circledcirc \mathbf{q}_i$$

여기서, $\circledcirc$는 벡터의 element-wise product이며, 마지막 output layer의 연산은 다음과 같다.



## 3.3 Multi-Layer Perceptron (MLP)



## 3.4 Fusion of GMF and MLP


### 3.4.1 Pre-training


---

# 4. Experiments


## 4.1 Experimental Settings


## 4.2 Performance Comparison (RQ1)


### 4.2.1 Utility of Pre-training



## 4.3 Log Loss with Negative Sampling (RQ2)


## 4.4 Is Deep Learning Helpful? (RQ3)



---

# 5. Related Work



---


# 6. Conclusion and Future Work




---

# 7. References